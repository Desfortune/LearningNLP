{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LearningNLP_Tutorial1.1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hISWdom_eFdQ"
      },
      "source": [
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MachineLearningJournalClub/LearningNLP/blob/main/LearningNLP_Tutorial1.ipynb)\n",
        "\n",
        "# Learning NLP Tutorial Series \n",
        "## Tutorial 1 : More Sentiment Analysis \n",
        "\n",
        "Topics include: \n",
        "* Exploring a dataset (Disaster Tweets, ArXiv) \n",
        "* Explainability methods : SHAP, LIME \n",
        "* Sentiment Analysis generalization to N classes \n",
        "\n",
        "(Authors: Luca Bottero, Simone Azeglio, Alessio Borriero)\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "## **Overview**\n",
        "\n",
        "* [Preprocessing](#section1)\n",
        "    * [Feature Engineering: feature extraction with count vectorizer and term frequency-inverse document frequency (tf-idf)](#section1.1)\n",
        "\n",
        "* [Classification](#section2)\n",
        "    * [Train a classifier](#section2.1)  \n",
        "    * [Prediction over test set](#section2.2)  \n",
        "    * [Evaluation](#section2.1)  \n",
        "\n",
        "* [Explainability Methods](#section2)\n",
        "    * [SHAP](#section2.1)\n",
        "    * [LIME](#section2.2)\n",
        "\n",
        "* [References & Additional Material](#section4)\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-MMBJOR6ePE"
      },
      "source": [
        "<a id=\"section1\"></a>\n",
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsrMEupxz9-P",
        "outputId": "71a6ad0b-4991-4069-d6eb-5edf2fa83310"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFAh_4eRun7A"
      },
      "source": [
        "The Arxiv dataset we will use is written in JSON, a syntax for storing and exchanging data.\n",
        "JSON is text, written with JavaScript object notation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce2vZGH9urYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeef63c8-f47c-4858-e590-2b295608fd07"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json   #importing this module we can work with JSON data\n",
        "import nltk   #NLP toolkit\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import re     # library for regular expression operations\n",
        "import string # for string operations\n",
        "import collections\n",
        "import gensim  \n",
        "from gensim import parsing        # Help in preprocessing the data, very efficiently\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLT2lAXDxtH8"
      },
      "source": [
        "With the function in the next cell we build an object called generator, i.e. a kind of iterable you can only iterate over once.\n",
        "A generator don't store all the values in memory.\n",
        "So, with the function get_metadata() you can open the file in order to manage it paper by paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4S3YATuuspm"
      },
      "source": [
        "def get_metadata():\n",
        "    with open('/content/drive/MyDrive/ColabNotebooks/arxiv-metadata-oai-snapshot.json') as f:\n",
        "        for line in f:\n",
        "            yield line #Yield is used like Return, except the function will return a generator"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxEbL_rWuss2"
      },
      "source": [
        "metadata = get_metadata()\n",
        "\n",
        "for paper in metadata:\n",
        "    first_paper = json.loads(paper) #json.loads() return a dictionary\n",
        "    break"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwL6aqgYuz4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebaf9142-eb06-4c06-a229-3ebd2f098500"
      },
      "source": [
        "for key in first_paper:\n",
        "    print(key)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id\n",
            "submitter\n",
            "authors\n",
            "title\n",
            "comments\n",
            "journal-ref\n",
            "doi\n",
            "report-no\n",
            "categories\n",
            "license\n",
            "abstract\n",
            "versions\n",
            "update_date\n",
            "authors_parsed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHUd8_HMu3V5"
      },
      "source": [
        "We're interested only in the keys Categories, Authors, Title and Abstract of each paper, so let's save this information in a Dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykryHbj_u4yt"
      },
      "source": [
        "#set of empty list that will be filled with the information of each paper\n",
        "\n",
        "categories = []\n",
        "authors = []\n",
        "title = []\n",
        "abstract = []"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RQSbi1ou56d"
      },
      "source": [
        "total_items = 0\n",
        "\n",
        "for papers in metadata:\n",
        "    paper = json.loads(papers)\n",
        "    \n",
        "    categories.append(paper['categories'])\n",
        "    authors.append(paper['authors'])\n",
        "    title.append(paper['title'])\n",
        "    abstract.append(paper['abstract'])\n",
        "    \n",
        "    total_items += 1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR58x4Z9u597",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18ea4f7c-7ca1-419c-eba2-b5f7dd10e745"
      },
      "source": [
        "print(total_items)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1796910\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2mdHTIxvDOJ"
      },
      "source": [
        "#In this cell we create a dictionary with the information stored before\n",
        "d = {\n",
        "    'Categories': categories,\n",
        "    'Authors': authors,\n",
        "    'Title': title,\n",
        "    'Abstract': abstract,\n",
        "}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_Gq36AZvDRY"
      },
      "source": [
        "df = pd.DataFrame(d)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJCddMyPvFVJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "b1c83afe-c7e5-4394-edf3-56fc78487d0a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Categories</th>\n",
              "      <th>Authors</th>\n",
              "      <th>Title</th>\n",
              "      <th>Abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>math.CO cs.CG</td>\n",
              "      <td>Ileana Streinu and Louis Theran</td>\n",
              "      <td>Sparsity-certifying Graph Decompositions</td>\n",
              "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>physics.gen-ph</td>\n",
              "      <td>Hongjun Pan</td>\n",
              "      <td>The evolution of the Earth-Moon system based o...</td>\n",
              "      <td>The evolution of Earth-Moon system is descri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>math.CO</td>\n",
              "      <td>David Callan</td>\n",
              "      <td>A determinant of Stirling cycle numbers counts...</td>\n",
              "      <td>We show that a determinant of Stirling cycle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>math.CA math.FA</td>\n",
              "      <td>Wael Abu-Shammala and Alberto Torchinsky</td>\n",
              "      <td>From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...</td>\n",
              "      <td>In this paper we show how to compute the $\\L...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cond-mat.mes-hall</td>\n",
              "      <td>Y. H. Pong and C. K. Law</td>\n",
              "      <td>Bosonic characters of atomic Cooper pairs acro...</td>\n",
              "      <td>We study the two-particle wave function of p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Categories  ...                                           Abstract\n",
              "0      math.CO cs.CG  ...    We describe a new algorithm, the $(k,\\ell)$-...\n",
              "1     physics.gen-ph  ...    The evolution of Earth-Moon system is descri...\n",
              "2            math.CO  ...    We show that a determinant of Stirling cycle...\n",
              "3    math.CA math.FA  ...    In this paper we show how to compute the $\\L...\n",
              "4  cond-mat.mes-hall  ...    We study the two-particle wave function of p...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-grrP_XcvJEV"
      },
      "source": [
        "In order to use this data for classification we have to prepocessing them, so we exploit Gensim library (reference at the following link https://radimrehurek.com/gensim/corpora/textcorpus.html).\n",
        "The following code has been ispired from the following notebook found on kaggle: https://www.kaggle.com/anurag3753/prediction-naive-bayes-preprocessing-with-gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8azoNkJvJKG"
      },
      "source": [
        "def transformText(text):\n",
        "    \n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    \n",
        "    # Convert text to lower\n",
        "    text = text.lower()\n",
        "    # Removing non ASCII chars    \n",
        "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
        "    \n",
        "    # Strip multiple whitespaces\n",
        "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
        "    \n",
        "    # Removing all the stopwords\n",
        "    filtered_words = [word for word in text.split() if word not in stops]\n",
        "    \n",
        "    # Removing all the tokens with lesser than 3 characters\n",
        "    filtered_words = gensim.corpora.textcorpus.remove_short(filtered_words, minsize=3)\n",
        "    \n",
        "    # Preprocessed text after stop words removal\n",
        "    text = \" \".join(filtered_words)\n",
        "    \n",
        "    # Remove the punctuation\n",
        "    text = gensim.parsing.preprocessing.strip_punctuation2(text)\n",
        "    \n",
        "    # Strip all the numerics\n",
        "    text = gensim.parsing.preprocessing.strip_numeric(text)\n",
        "    \n",
        "    # Strip multiple whitespaces\n",
        "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
        "    \n",
        "    # Stemming\n",
        "    return gensim.parsing.preprocessing.stem_text(text)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97xaIwryvMs7"
      },
      "source": [
        "df['Title'] = df['Title'].map(transformText)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyQjjybpvM7Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "85cff1b3-eff5-4a89-a264-09dedb6cef15"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Categories</th>\n",
              "      <th>Authors</th>\n",
              "      <th>Title</th>\n",
              "      <th>Abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>math.CO cs.CG</td>\n",
              "      <td>Ileana Streinu and Louis Theran</td>\n",
              "      <td>sparsiti certifi graph decomposit</td>\n",
              "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>physics.gen-ph</td>\n",
              "      <td>Hongjun Pan</td>\n",
              "      <td>evolut earth moon system base dark matter fiel...</td>\n",
              "      <td>The evolution of Earth-Moon system is descri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>math.CO</td>\n",
              "      <td>David Callan</td>\n",
              "      <td>determin stirl cycl number count unlabel acycl...</td>\n",
              "      <td>We show that a determinant of Stirling cycle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>math.CA math.FA</td>\n",
              "      <td>Wael Abu-Shammala and Alberto Torchinsky</td>\n",
              "      <td>dyadic lambda alpha lambda alpha</td>\n",
              "      <td>In this paper we show how to compute the $\\L...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cond-mat.mes-hall</td>\n",
              "      <td>Y. H. Pong and C. K. Law</td>\n",
              "      <td>boson charact atom cooper pair across reson</td>\n",
              "      <td>We study the two-particle wave function of p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Categories  ...                                           Abstract\n",
              "0      math.CO cs.CG  ...    We describe a new algorithm, the $(k,\\ell)$-...\n",
              "1     physics.gen-ph  ...    The evolution of Earth-Moon system is descri...\n",
              "2            math.CO  ...    We show that a determinant of Stirling cycle...\n",
              "3    math.CA math.FA  ...    In this paper we show how to compute the $\\L...\n",
              "4  cond-mat.mes-hall  ...    We study the two-particle wave function of p...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB_lxf8ZvTg7"
      },
      "source": [
        "First we have to chose only two Categories in order to perform our binary classification. At the page https://arxiv.org/category_taxonomy you can find the complete ArXiv categories taxonomy. So, for our purpose we chose the two more frequent categories. Let's find them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4RjZTpmvT2u"
      },
      "source": [
        "categories = df.Categories"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w0BuxTevYpB"
      },
      "source": [
        "cat_freq_dic = collections.Counter(categories) #collections.Counter gives us a dictionary with a count of how many \n",
        "                                               #times a category appears in the dataset"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kQwmpm1vYxc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca9b5893-bd15-4544-b569-2e2e86e79150"
      },
      "source": [
        "max1 = 0\n",
        "max2 = 0\n",
        "for key in cat_freq_dic:\n",
        "    if  cat_freq_dic[key]>max1:\n",
        "        max1=cat_freq_dic[key]\n",
        "        max1key=key\n",
        "    elif cat_freq_dic[key]>max2:\n",
        "        max2=cat_freq_dic[key]\n",
        "        max2key=key        \n",
        "            \n",
        "print(max1key, max1)\n",
        "print(max2key, max2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "astro-ph 86914\n",
            "hep-ph 73549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_Rx7wBXvclf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "05518ccf-8a46-41ca-d9a5-61aa36134d7a"
      },
      "source": [
        "traindf = df[(df['Categories']==max2key) | (df['Categories']==max1key)]\n",
        "traindf.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Categories</th>\n",
              "      <th>Authors</th>\n",
              "      <th>Title</th>\n",
              "      <th>Abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>astro-ph</td>\n",
              "      <td>Paul Harvey, Bruno Merin, Tracy L. Huard, Luis...</td>\n",
              "      <td>spitzer cd survei larg nearbi insterstellar cl...</td>\n",
              "      <td>We discuss the results from the combined IRA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>hep-ph</td>\n",
              "      <td>Chao-Hsi Chang, Tong Li, Xue-Qian Li and Yu-Mi...</td>\n",
              "      <td>lifetim doubli charm baryon</td>\n",
              "      <td>In this work, we evaluate the lifetimes of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>astro-ph</td>\n",
              "      <td>Nceba Mhlahlo, David H. Buckley, Vikram S. Dhi...</td>\n",
              "      <td>spectroscop observ intermedi polar hydra quies...</td>\n",
              "      <td>Results from spectroscopic observations of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>astro-ph</td>\n",
              "      <td>M. A. Loukitcheva, S. K. Solanki and S. White</td>\n",
              "      <td>alma ideal probe solar chromospher</td>\n",
              "      <td>The very nature of the solar chromosphere, i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>hep-ph</td>\n",
              "      <td>Zhan Shu, Xiao-Lin Chen and Wei-Zhen Deng</td>\n",
              "      <td>understand flavor symmetri break nucleon flavo...</td>\n",
              "      <td>In $\\XQM$, a quark can emit Goldstone bosons...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Categories  ...                                           Abstract\n",
              "7    astro-ph  ...    We discuss the results from the combined IRA...\n",
              "14     hep-ph  ...    In this work, we evaluate the lifetimes of t...\n",
              "15   astro-ph  ...    Results from spectroscopic observations of t...\n",
              "21   astro-ph  ...    The very nature of the solar chromosphere, i...\n",
              "27     hep-ph  ...    In $\\XQM$, a quark can emit Goldstone bosons...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMy7tKYMvi1L"
      },
      "source": [
        "Now that only two categories has been selected, we have to convert categories names in a digits in order to be processed by a classification algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYgbJMNSvcrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f20abda9-acb8-4768-be59-fe1820f217fa"
      },
      "source": [
        "category_to_id = {    #create a simple dictionary which map the category in a digit\n",
        "    max1key: 0,\n",
        "    max2key: 1\n",
        "}\n",
        "\n",
        "def get_category_id(category):\n",
        "    return category_to_id[category]\n",
        "\n",
        "traindf['Categories'] = traindf['Categories'].map(get_category_id)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O1nre0rvlny",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "e5310398-0999-48ec-fb1e-ab5fba135ef7"
      },
      "source": [
        "traindf.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Categories</th>\n",
              "      <th>Authors</th>\n",
              "      <th>Title</th>\n",
              "      <th>Abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>Paul Harvey, Bruno Merin, Tracy L. Huard, Luis...</td>\n",
              "      <td>spitzer cd survei larg nearbi insterstellar cl...</td>\n",
              "      <td>We discuss the results from the combined IRA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>Chao-Hsi Chang, Tong Li, Xue-Qian Li and Yu-Mi...</td>\n",
              "      <td>lifetim doubli charm baryon</td>\n",
              "      <td>In this work, we evaluate the lifetimes of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>Nceba Mhlahlo, David H. Buckley, Vikram S. Dhi...</td>\n",
              "      <td>spectroscop observ intermedi polar hydra quies...</td>\n",
              "      <td>Results from spectroscopic observations of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>M. A. Loukitcheva, S. K. Solanki and S. White</td>\n",
              "      <td>alma ideal probe solar chromospher</td>\n",
              "      <td>The very nature of the solar chromosphere, i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>Zhan Shu, Xiao-Lin Chen and Wei-Zhen Deng</td>\n",
              "      <td>understand flavor symmetri break nucleon flavo...</td>\n",
              "      <td>In $\\XQM$, a quark can emit Goldstone bosons...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Categories  ...                                           Abstract\n",
              "7            0  ...    We discuss the results from the combined IRA...\n",
              "14           1  ...    In this work, we evaluate the lifetimes of t...\n",
              "15           0  ...    Results from spectroscopic observations of t...\n",
              "21           0  ...    The very nature of the solar chromosphere, i...\n",
              "27           1  ...    In $\\XQM$, a quark can emit Goldstone bosons...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihuK2Zu5vp9b"
      },
      "source": [
        "Once we have properly preprocess our data, we have to split the dataset in training and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aafMIAzVvlqn"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(traindf['Title'], traindf['Categories'], \n",
        "                                                    test_size=0.33, random_state=42)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqEku8ZWvlu6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f83c61a-b3e5-43f4-9cc1-6e75ddc04364"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "338205                     save fourth gener higg radion mix\n",
              "1395428                                   infrar color dwarf\n",
              "1414457                            growth hii region reioniz\n",
              "1431266    spitzer space telescop extra galact first look...\n",
              "1427474    lyman alpha radiat collaps protogalaxi ii obse...\n",
              "                                 ...                        \n",
              "1460445                      flight determin plate scale eit\n",
              "1443002               orion ob associ ii orion eridanu bubbl\n",
              "1599370    numer evalu master integr loop gener massiv se...\n",
              "1618623          effect shadow doubl pomeron exchang process\n",
              "1585877                         issu flat direct baryogenesi\n",
              "Name: Title, Length: 107510, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR9B3KzKv6e9"
      },
      "source": [
        "<a id='section1.1'></a>\n",
        "# Feature Engineering: feature extraction with count vectorizer and term frequency-inverse document frequency (tfidf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xN5bKi-v6hd"
      },
      "source": [
        "Now we have to create the features will feed our classification model. In order to do that we exploit to methods: CountVectorizer and TfidfTransofer. \n",
        "\n",
        "CountVectorizer (reference at the following link https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) is able to create a dictionary of word inside all the documents we provide to it and than to represent each of this documents (the titles) in a matrix form. Every row will be a title and every column a word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4fKKCpMvlxt"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMbCePakwCL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5409a70b-e97e-4de8-988a-7e771ebda72e"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X_train_counts = vectorizer.fit_transform(X_train)\n",
        "features_name = vectorizer.get_feature_names()\n",
        "features_name[:10]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aa', 'aaa', 'aal', 'aamq', 'aao', 'aaomega', 'aat', 'aavso', 'ab', 'aband']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1veHF3fwGhh"
      },
      "source": [
        "Because of the high number of word in the vocabulary, the resulting matrix after applying CountVectorizer to our data is a sparse matrix, with most of its values equal to zero. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRXEwqNuwCO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "689b8a0c-0bdb-4c43-fe46-4eb246d45ed6"
      },
      "source": [
        "len(features_name)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13199"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di9mhLlwwMAD"
      },
      "source": [
        "After the data manipulation above, we have to use the TfidfTransformer (reference at the following link https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer) in order to create a proper count of the frequency of each word inside our dataset. Tf-idf is the acronym for Term Frequncy-Inverse Document Frequency. With this approach mw evaluate the relative importance of particular word. Tf-idf is the product of two statistics, term frequency and inverse document frequency. Various ways for determining the exact values of both statistics exist. In the case of the Term Frequency is the \"raw frequency\" of a term in a document, i.e. the number of times a term occurs in document (a title). The \"inverse document frequency\" is a measure of whether the term is common or rare across all documents. It is obtained by dividing the total number of documents by the number of documents containing the term, and then taking the logarithm of that quotient. The Tf-idf is the product of this two quantity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlV7dLFVwMOX"
      },
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y4caJh0wR76"
      },
      "source": [
        "<a id='section2'></a>\n",
        "# **Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hOy7uui72Ta"
      },
      "source": [
        "<a id='section2.1'></a>\n",
        "# Train a classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cHOcGOdwSvE"
      },
      "source": [
        "We choose Logistic Regression as classification model. Instead of making a manual implemetation of this model, we exploit the sklearn method for Logistic Regression (reference at the following link https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCG6dgL8wS2s"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "regression = LogisticRegression()\n",
        "regression.fit(X_train_tfidf, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JApBnlNowgfh"
      },
      "source": [
        "<a id='section2.2'></a>\n",
        "# Prediction over test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQw8O3afwgiG"
      },
      "source": [
        "Pay attention to the methods used to countvectorize the test set. In this case we use CountVectorizer.transform() instead of CountVectorizer.fit_transform() in order to mantain the vocabulary built before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42TE6_IowS5_"
      },
      "source": [
        "X_test_counts = vectorizer.transform(X_test)\n",
        "features_name = vectorizer.get_feature_names()\n",
        "features_name[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmpTvKnHwpbs"
      },
      "source": [
        "X_test_tfidf = tfidf_transformer.fit_transform(X_test_counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9C5W8T-wpkF"
      },
      "source": [
        "prediction = regression.predict(X_test_tfidf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aH60CLBwter"
      },
      "source": [
        "<a id='section2.3'></a>\n",
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBgXmV5jwwkG"
      },
      "source": [
        "np.mean(prediction == y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb5jDscafLIy"
      },
      "source": [
        "\n",
        "<a id='section2'></a>\n",
        "# **Explainability Methods**\n",
        "Explainability .... \n",
        "\n",
        "<a id='section2.1'></a>\n",
        "## **SHAP**\n",
        "SHAP ipsum lorem \n",
        "\n",
        "<a id='section2.2'></a>\n",
        "## **LIME**\n",
        "Lime ipsum lorem "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHLaBRQtfLN7"
      },
      "source": [
        ""
      ]
    }
  ]
}